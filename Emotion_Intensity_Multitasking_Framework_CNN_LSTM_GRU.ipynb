{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oq_YXEpdgtRF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pydotplus\n",
        "import pydot\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA0dPpOogtRJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVtmspyfgtRL"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers import Input, Dense, Flatten, LSTM, GRU, Conv1D,Conv2D, MaxPooling1D, Dropout, Activation, Concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuFZb9nvgtRN"
      },
      "outputs": [],
      "source": [
        "path = os.getcwd()\n",
        "all_files = glob.glob(os.path.join(path, \"*.txt\"))\n",
        "df_from_each_file = [ pd.read_csv(file,sep=\"\\t\", header=None) for file in all_files]\n",
        "df = pd.concat(df_from_each_file, ignore_index=True)\n",
        "df.columns = [\"Sr. No.\", \"Tweet\", \"Class\",\"Intensity\"]\n",
        "df=df.sample(frac=1)\n",
        "pd.set_option('display.max_colwidth', -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7okZr3d6gtRO"
      },
      "outputs": [],
      "source": [
        "df[df['Class']=='fear'].sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPvhifa2gtRP"
      },
      "outputs": [],
      "source": [
        "import preprocessor as p\n",
        "from gensim.parsing.preprocessing import *\n",
        "\n",
        "def preprocess_tweet(row):\n",
        "    text = row['Tweet']\n",
        "    text = p.clean(text)\n",
        "    return text\n",
        "\n",
        "def stopword_removal(row):\n",
        "    text = row['Tweet']\n",
        "    text = remove_stopwords(text)\n",
        "    return text\n",
        "\n",
        "def lower_casing(row):\n",
        "    text = row['Tweet']\n",
        "    text = text.lower().replace('[^\\w\\s]',' ').replace('\\s\\s+', ' ')\n",
        "    return text\n",
        "\n",
        "def keep_aplhaNumerics_Only(row):\n",
        "    text = row['Tweet']\n",
        "    text = strip_non_alphanum(text)\n",
        "    return text\n",
        "\n",
        "def preprocessData(df):\n",
        "    df['Tweet'] = df.apply(preprocess_tweet, axis=1)\n",
        "    df['Tweet'] = df.apply(stopword_removal, axis=1)\n",
        "    df['Tweet'] = df.apply(keep_aplhaNumerics_Only, axis=1)\n",
        "    df['Tweet'] = df.apply(lower_casing, axis=1)\n",
        "    X = df['Tweet']\n",
        "    Y = df[['Class','Intensity']]\n",
        "    return X.to_numpy(),Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUJn_H9UgtRR"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = preprocessData(df)\n",
        "tokenizer = Tokenizer(num_words= 200000) \n",
        "tokenizer.fit_on_texts(X_train)\n",
        "sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_train_encoded = pad_sequences(sequences, maxlen=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCXgexOggtRS"
      },
      "outputs": [],
      "source": [
        "Y1_train = Y_train['Class']\n",
        "Y2_train = Y_train['Intensity']\n",
        "le = LabelEncoder()\n",
        "\n",
        "Y1_train_encoded = le.fit_transform(Y1_train)\n",
        "Y1_train_encoded = to_categorical(Y1_train_encoded)\n",
        "Y2_train_encoded = Y2_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7Ez3845gtRT"
      },
      "outputs": [],
      "source": [
        "Y1_train = le.inverse_transform(Y1_train)\n",
        "word_index = tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9wHe5d5gtRU"
      },
      "outputs": [],
      "source": [
        "embeddings_index = {}\n",
        "with open(\"glove.6B/glove.6B.300d.txt\",encoding=\"utf8\") as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojhyGUEdgtRV"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = len(tokenizer.word_index) + 2\n",
        "EMBEDDING_DIM = 300\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "\n",
        "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r6pdfFigtRW"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSdy2ZhsgtRX"
      },
      "outputs": [],
      "source": [
        "def LSTM_model(task):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, weights = [embedding_matrix], trainable=True, input_length=X_train_encoded.shape[1]))\n",
        "    #model.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=X_train_encoded.shape[1]))\n",
        "    model.add(LSTM(128,activation='relu',return_sequences=True))\n",
        "    model.add(LSTM(128,activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128,activation='relu'))\n",
        "    model.add(Dense(100,activation='relu'))\n",
        "\n",
        "    if task == \"Classification\":\n",
        "        model.add(Dense(4, activation='softmax'))\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    elif task ==\"Regression\":\n",
        "        model.add(Dense(1,activation='sigmoid'))\n",
        "        model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mse',pearson_r])\n",
        "    else:\n",
        "        print(\"ERROR: INVALID TASK\")\n",
        "        return\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do3rPJEXgtRX"
      },
      "source": [
        "### GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cQJ6HVSgtRY"
      },
      "outputs": [],
      "source": [
        "def GRU_model(task):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, weights = [embedding_matrix], trainable=True, input_length=X_train_encoded.shape[1]))\n",
        "    #model.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=X_train_encoded.shape[1]))\n",
        "    model.add(GRU(128,activation='relu',return_sequences=True))\n",
        "    model.add(GRU(128,activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128,activation='relu'))\n",
        "    model.add(Dense(100,activation='relu'))\n",
        "\n",
        "    if task == \"Classification\":\n",
        "        model.add(Dense(4, activation='softmax'))\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    elif task ==\"Regression\":\n",
        "        model.add(Dense(1,activation='sigmoid'))\n",
        "        model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mse',pearson_r])\n",
        "    else:\n",
        "        print(\"ERROR: INVALID TASK\")\n",
        "        return\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfsjopfZgtRY"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amRvtggcgtRZ"
      },
      "outputs": [],
      "source": [
        "def CNN_model(task):\n",
        "    Input_layer     = Input(shape = X_train_encoded.shape[1], name=\"Input_layer\")\n",
        "    Embedding_layer = Embedding(VOCAB_SIZE, EMBEDDING_DIM,weights = [embedding_matrix],trainable=True, input_length=X_train_encoded.shape[1], name=\"Embedding_layer\")(Input_layer)\n",
        "    #Embedding_layer = Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=X_train_encoded.shape[1])(Input_layer)\n",
        "    CNN1_layer1     = Conv1D(100, kernel_size=2, padding=\"same\", activation=\"relu\")(Embedding_layer)\n",
        "    CNN1_layer2     = Conv1D(100, kernel_size=3, padding=\"same\", activation=\"relu\")(Embedding_layer)\n",
        "    CNN1_layer3     = Conv1D(100, kernel_size=4, padding=\"same\", activation=\"relu\")(Embedding_layer)\n",
        "    Concat_layer1   = Concatenate(axis=1)([CNN1_layer1, CNN1_layer2, CNN1_layer3])\n",
        "    Pool_layer1     = MaxPooling1D(pool_size=2)(Concat_layer1)\n",
        "    CNN2_layer1     = Conv1D(100, kernel_size=2, padding=\"same\", activation=\"relu\")(Pool_layer1)\n",
        "    CNN2_layer2     = Conv1D(100, kernel_size=3, padding=\"same\", activation=\"relu\")(Pool_layer1)\n",
        "    CNN2_layer3     = Conv1D(100, kernel_size=4, padding=\"same\", activation=\"relu\")(Pool_layer1)\n",
        "    Concat_layer2   = Concatenate(axis=1)([CNN2_layer1, CNN2_layer2, CNN2_layer3])\n",
        "    Pool_layer2     = MaxPooling1D(pool_size=2)(Concat_layer2)\n",
        "    Flatten_layer   = Flatten()(Pool_layer2)\n",
        "    Dense_layer1    = Dense(128,activation='relu', name=\"Dense_layer1a\")(Flatten_layer)\n",
        "    Dense_layer2    = Dense(100,activation='relu', name=\"Dense_layer1b\")(Dense_layer1)\n",
        "\n",
        "    if task == \"Classification\":\n",
        "        predictions_task1 = Dense(4, activation='softmax', name=\"predictions_task1\")(Dense_layer2)\n",
        "        model= tf.keras.models.Model(Input_layer,predictions_task1)\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    elif task ==\"Regression\":\n",
        "        predictions_task2 = Dense(1, activation='sigmoid', name=\"predictions_task2\")(Dense_layer2)\n",
        "        model= tf.keras.models.Model(Input_layer,predictions_task2)\n",
        "        model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mse',pearson_r])\n",
        "    else:\n",
        "        print(\"ERROR: INVALID TASK\")\n",
        "        return\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMGVYQjxgtRc"
      },
      "outputs": [],
      "source": [
        "def getAccuracy(model, X, Y):\n",
        "    history = model.fit(X,Y, epochs=40, batch_size=64,validation_split=0.1,\n",
        "                        callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
        "\n",
        "    # summarize history for accuracy\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    return history.history['accuracy'],history.history['val_accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLHShinOgtRj"
      },
      "outputs": [],
      "source": [
        "def getPearsonR(model, X, Y):\n",
        "    history = model.fit(X,Y, epochs=40, batch_size=64,validation_split=0.1,\n",
        "                        callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
        "\n",
        "    # summarize history for accuracy\n",
        "    plt.plot(history.history['pearson_r'])\n",
        "    plt.plot(history.history['val_pearson_r'])\n",
        "    plt.title('Model Pearsn R Coefficient')\n",
        "    plt.ylabel('pearson_r')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    return history.history['pearson_r'],history.history['val_pearson_r']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41wekDsHgtRk"
      },
      "outputs": [],
      "source": [
        "task1 = \"Classification\"\n",
        "task2 = \"Regression\"\n",
        "\n",
        "Results_Task1=dict()\n",
        "Results_Task2=dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "No4ASBi1gtRl"
      },
      "outputs": [],
      "source": [
        "print(\"LSTM Model\\n\\n\")\n",
        "acc, val_acc = getAccuracy(LSTM_model(task1), X_train_encoded, Y1_train_encoded)\n",
        "Results_Task1['LSTM']={'Accuracy':acc[-1],'Val_Accuracy':val_acc[-1]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAa1x9ySgtRl"
      },
      "outputs": [],
      "source": [
        "print(\"GRU Model\\n\\n\")\n",
        "acc, val_acc = getAccuracy(GRU_model(task1), X_train_encoded, Y1_train_encoded)\n",
        "Results_Task1['GRU']={'Accuracy':acc[-1],'Val_Accuracy':val_acc[-1]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgWIJRnygtRl"
      },
      "outputs": [],
      "source": [
        "print(\"CNN Model\\n\\n\")\n",
        "acc, val_acc = getAccuracy(CNN_model(task1), X_train_encoded, Y1_train_encoded)\n",
        "Results_Task1['CNN']={'Accuracy':acc[-1],'Val_Accuracy':val_acc[-1]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WQHsxEngtRm"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "def pearson_r(y_true, y_pred):\n",
        "    x = y_true\n",
        "    y = y_pred\n",
        "    mx = K.mean(x, axis=0)\n",
        "    my = K.mean(y, axis=0)\n",
        "    xm, ym = x - mx, y - my\n",
        "    r_num = K.sum(xm * ym)\n",
        "    x_square_sum = K.sum(xm * xm)\n",
        "    y_square_sum = K.sum(ym * ym)\n",
        "    r_den = K.sqrt(x_square_sum * y_square_sum)\n",
        "    r = r_num / r_den\n",
        "    return K.mean(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSGTEDLxgtRz"
      },
      "outputs": [],
      "source": [
        "print(\"LSTM Model\\n\\n\")\n",
        "pearson_r, val_pearson_r = getPearsonR(LSTM_model(task2), X_train_encoded, Y2_train_encoded)\n",
        "Results_Task2['LSTM']={'pearson_r':pearson_r[-1],'Val_pearson_r':val_pearson_r[-1]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bAnKxkUgtRz"
      },
      "outputs": [],
      "source": [
        "print(\"GRU Model\\n\\n\")\n",
        "pearson_r, val_pearson_r = getPearsonR(GRU_model(task2), X_train_encoded, Y2_train_encoded)\n",
        "Results_Task2['GRU']={'pearson_r':pearson_r[-1],'Val_pearson_r':val_pearson_r[-1]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBv22UKxgtRz"
      },
      "outputs": [],
      "source": [
        "print(\"CNN Model\\n\\n\")\n",
        "pearson_r, val_pearson_r = getPearsonR(CNN_model(task2), X_train_encoded, Y2_train_encoded)\n",
        "Results_Task2['CNN']={'pearson_r':pearson_r[-1],'Val_pearson_r':val_pearson_r[-1]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKddMklUgtR0"
      },
      "outputs": [],
      "source": [
        "print(\"Single Task Framework - Task 1 Results\\n\")\n",
        "# Print the names of the column\n",
        "print (\"{:<10} {:<15} {:<10}\".format('Model', 'Train Accuracy', ' Test Accuracy'))\n",
        "\n",
        "# print each data item.\n",
        "for key, value in Results_Task1.items():\n",
        "    train_acc = round(value['Accuracy'],3)\n",
        "    val_acc   = round(value['Val_Accuracy'],3)\n",
        "    print (\"{:<10} {:<17} {:<10}\".format(key, train_acc, val_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FayoZeLwgtR0"
      },
      "outputs": [],
      "source": [
        "print(\"Single Task Framework - Task 2 Results\\n\")\n",
        "print (\"{:<10} {:<15} {:<10}\".format('Model', 'Train pearson_r', ' Val pearson_r'))\n",
        "\n",
        "for key, value in Results_Task2.items():\n",
        "    train_acc = round(value['pearson_r'],3)\n",
        "    val_acc   = round(value['Val_pearson_r'],3)\n",
        "    print (\"{:<10} {:<17} {:<10}\".format(key, train_acc, val_acc))"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "Ic8C71qrgtR0"
      },
      "source": [
        "new_tweet = ['Ohh no! The results are not impressive']\n",
        "seq = tokenizer.texts_to_sequences(new_tweet)\n",
        "padded = pad_sequences(seq, maxlen=30)\n",
        "pred = model.predict(padded)\n",
        "labels=['anger','fear','joy','sadness']\n",
        "print(pred, labels[np.argmax(pred)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gul4lrGzgtR1"
      },
      "source": [
        "#\n",
        "# __Multi-tasking Framework__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvqdUGpugtR1"
      },
      "outputs": [],
      "source": [
        "Multitask_Results_Task1 = {}\n",
        "Multitask_Results_Task2 = {}\n",
        "alpha = 0.185"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5NDa8argtR2"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "def pearson_r(y_true, y_pred):\n",
        "    x = y_true\n",
        "    y = y_pred\n",
        "    mx = K.mean(x, axis=0)\n",
        "    my = K.mean(y, axis=0)\n",
        "    xm, ym = x - mx, y - my\n",
        "    r_num = K.sum(xm * ym)\n",
        "    x_square_sum = K.sum(xm * xm)\n",
        "    y_square_sum = K.sum(ym * ym)\n",
        "    r_den = K.sqrt(x_square_sum * y_square_sum)\n",
        "    r = r_num / r_den\n",
        "    return K.mean(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJEfohLAgtR3"
      },
      "outputs": [],
      "source": [
        "def create_multihead_LSTM_model(X):\n",
        "    #Shared Layers\n",
        "    Input_layer       = Input(shape = X.shape[1], name=\"Input_layer\")\n",
        "    Embedding_layer   = Embedding(VOCAB_SIZE, EMBEDDING_DIM,weights = [embedding_matrix], trainable=True, input_length=X.shape[1], name=\"Embedding_layer\")(Input_layer)\n",
        "    #Embedding_layer  = Embedding(VOCAB_SIZE,EMBEDDING_DIM, input_length=X.shape[1], name=\"Embedding_layer\")(Input_layer)\n",
        "    LSTM_layer1       = LSTM(128,activation='relu', return_sequences=True, name=\"LSTM_layer1\" )(Embedding_layer)\n",
        "    LSTM_layer2       = LSTM(128,activation='relu', name=\"LSTM_layer2\")(LSTM_layer1)\n",
        "    Dropout_layer     = Dropout(0.25, name=\"Dropout_layer\")(LSTM_layer2)\n",
        "\n",
        " \n",
        "    Dense_layer1a     = Dense(128,activation='relu', name=\"Dense_layer1a\")(Dropout_layer)\n",
        "    Dense_layer1b     = Dense(100,activation='relu', name=\"Dense_layer1b\")(Dense_layer1a)\n",
        "\n",
        "  \n",
        "    Dense_layer2a     = Dense(128,activation='relu', name=\"Dense_layer2a\")(Dropout_layer)\n",
        "    Dense_layer2b     = Dense(100,activation='relu', name=\"Dense_layer2b\")(Dense_layer2a)\n",
        "\n",
        "  \n",
        "    predictions_task1 = Dense(4, activation='softmax', name=\"predictions_task1\")(Dense_layer1b)\n",
        "    predictions_task2 = Dense(1, name=\"predictions_task2\")(Dense_layer2b)\n",
        "\n",
        "    model= tf.keras.models.Model(Input_layer, [predictions_task1,predictions_task2])\n",
        "    model.compile( loss= {'predictions_task1':'categorical_crossentropy' , 'predictions_task2':'mean_absolute_error' },\n",
        "                   loss_weights=[alpha,1-alpha],\n",
        "                   optimizer='adam',\n",
        "                   metrics={'predictions_task1':'accuracy' , 'predictions_task2':pearson_r },\n",
        "                 )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3JkLz1BgtR3"
      },
      "outputs": [],
      "source": [
        "Multihead_LSTM_model = create_multihead_LSTM_model(X_train_encoded)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "YqP0XeIkgtR3"
      },
      "source": [
        "Multihead_LSTM_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZCCpwqXgtR3"
      },
      "outputs": [],
      "source": [
        "Multihead_LSTM_model_history = Multihead_LSTM_model.fit(X_train_encoded, [Y1_train_encoded,Y2_train_encoded], epochs=40, batch_size=64,validation_split=0.1,\n",
        "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38QBxdrRgtR4"
      },
      "outputs": [],
      "source": [
        "plt.plot(Multihead_LSTM_model_history.history['predictions_task1_accuracy'])\n",
        "plt.plot(Multihead_LSTM_model_history.history['val_predictions_task1_accuracy'])\n",
        "plt.title('Multitasking LSTM Model Accuracy Task 1')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChPVMLeGgtR5"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.plot(Multihead_LSTM_model_history.history['predictions_task2_pearson_r'])\n",
        "plt.plot(Multihead_LSTM_model_history.history['val_predictions_task2_pearson_r'])\n",
        "plt.title('Multitasking LSTM Model Pearson R Task 2')\n",
        "plt.ylabel(' Pearson R')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(Multihead_LSTM_model_history.history['predictions_task2_loss'])\n",
        "plt.plot(Multihead_LSTM_model_history.history['val_predictions_task2_loss'])\n",
        "plt.title('Multitasking LSTM Model Loss Task 2')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8tugI5SgtR5"
      },
      "outputs": [],
      "source": [
        "Multitask_Results_Task1['LSTM'] ={'Accuracy':Multihead_LSTM_model_history.history['predictions_task1_accuracy'][-1],\n",
        "                                  'Val_Accuracy':Multihead_LSTM_model_history.history['val_predictions_task1_accuracy'][-1]\n",
        "                                 }\n",
        "Multitask_Results_Task2['LSTM'] ={'pearson_r':Multihead_LSTM_model_history.history['predictions_task2_pearson_r'][-1],\n",
        "                                  'Val_pearson_r':Multihead_LSTM_model_history.history['val_predictions_task2_pearson_r'][-1]}"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "PU0zpQh2gtR6"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(Multihead_LSTM_model, to_file='LSTM_model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBtCEAAugtR6"
      },
      "source": [
        "### Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjQ4YVJIgtR7"
      },
      "outputs": [],
      "source": [
        "def create_multihead_GRU_model(X):\n",
        "    #Shared Layers\n",
        "    Input_layer       = Input(shape = X.shape[1], name=\"Input_layer\")\n",
        "    Embedding_layer   = Embedding(VOCAB_SIZE, EMBEDDING_DIM,weights = [embedding_matrix], trainable=True, input_length=X.shape[1], name=\"Embedding_layer\")(Input_layer)\n",
        "    #Embedding_layer   = Embedding(VOCAB_SIZE,EMBEDDING_DIM, input_length=X.shape[1], name=\"Embedding_layer\")(Input_layer)\n",
        "    GRU_layer1        = GRU(128,activation='relu', return_sequences=True, name=\"GRU_layer1\" )(Embedding_layer)\n",
        "    GRU_layer2        = GRU(128,activation='relu', name=\"GRU_layer2\")(GRU_layer1)\n",
        "    Dropout_layer     = Dropout(0.25, name=\"Dropout_layer\")(GRU_layer2)\n",
        "\n",
        "    #Task Specific Layer for Task 1\n",
        "    Dense_layer1a     = Dense(128,activation='relu', name=\"Dense_layer1a\")(Dropout_layer)\n",
        "    Dense_layer1b     = Dense(100,activation='relu', name=\"Dense_layer1b\")(Dense_layer1a)\n",
        "\n",
        "    #Task Specific Layer for Task 2\n",
        "    Dense_layer2a     = Dense(128,activation='relu', name=\"Dense_layer2a\")(Dropout_layer)\n",
        "    Dense_layer2b     = Dense(100,activation='relu', name=\"Dense_layer2b\")(Dense_layer2a)\n",
        "\n",
        "    # Predictions for each task\n",
        "    predictions_task1 = Dense(4, activation='softmax', name=\"predictions_task1\")(Dense_layer1b)\n",
        "    predictions_task2 = Dense(1, activation='sigmoid', name=\"predictions_task2\")(Dense_layer2b)\n",
        "\n",
        "    model= tf.keras.models.Model(Input_layer, [predictions_task1,predictions_task2])\n",
        "    model.compile( loss= {'predictions_task1':'categorical_crossentropy' , 'predictions_task2':'mean_absolute_error' },\n",
        "                   loss_weights=[alpha,1-alpha],\n",
        "                   optimizer='adam',\n",
        "                   metrics={'predictions_task1':'accuracy' , 'predictions_task2':pearson_r },\n",
        "                 )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErHprs60gtR7"
      },
      "outputs": [],
      "source": [
        "Multihead_GRU_model = create_multihead_GRU_model(X_train_encoded)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "t1nfvSAXgtR7"
      },
      "source": [
        "Multihead_GRU_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V0HtobwgtR7"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xapmm3ETgtR7"
      },
      "outputs": [],
      "source": [
        "Multihead_GRU_model_history = Multihead_GRU_model.fit(X_train_encoded, [Y1_train_encoded,Y2_train_encoded], epochs=40, batch_size=64,validation_split=0.1,\n",
        "                     callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTGTm3U1gtR7"
      },
      "source": [
        "### Summarize Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDU45ecogtR7"
      },
      "outputs": [],
      "source": [
        "# Summarize history for Task 1\n",
        "plt.plot(Multihead_GRU_model_history.history['predictions_task1_accuracy'])\n",
        "plt.plot(Multihead_GRU_model_history.history['val_predictions_task1_accuracy'])\n",
        "plt.title('Multitasking Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89WTU-WcgtR8"
      },
      "outputs": [],
      "source": [
        "# Summarize history for Task 2\n",
        "plt.plot(Multihead_GRU_model_history.history['predictions_task2_pearson_r'])\n",
        "plt.plot(Multihead_GRU_model_history.history['val_predictions_task2_pearson_r'])\n",
        "plt.title('Multitasking Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCthKruTgtR8"
      },
      "outputs": [],
      "source": [
        "Multitask_Results_Task1['GRU'] ={'Accuracy':Multihead_GRU_model_history.history['predictions_task1_accuracy'][-1],\n",
        "                                  'Val_Accuracy':Multihead_GRU_model_history.history['val_predictions_task1_accuracy'][-1]}\n",
        "Multitask_Results_Task2['GRU'] ={'pearson_r':Multihead_GRU_model_history.history['predictions_task2_pearson_r'][-1],\n",
        "                                  'Val_pearson_r':Multihead_GRU_model_history.history['val_predictions_task2_pearson_r'][-1]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVGCBNFkgtR8"
      },
      "source": [
        "### Plotting Model Architecture"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "_vEqPPdSgtR8"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(Multihead_GRU_model, to_file='GRU_model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0YBdwrigtR-"
      },
      "source": [
        "## __Multi-tasking CNN Model__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF8urxzPgtR-"
      },
      "source": [
        "### Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTQsgFrwgtR-"
      },
      "outputs": [],
      "source": [
        "def create_multihead_CNN_model(X):\n",
        "    #Shared Layers\n",
        "    Input_layer       = Input(shape = X.shape[1], name=\"Input_layer\")\n",
        "    Embedding_layer   = Embedding(VOCAB_SIZE, EMBEDDING_DIM,weights = [embedding_matrix], trainable=True, input_length=X.shape[1], name=\"Embedding_layer\")(Input_layer)\n",
        "    #Embedding_layer  = Embedding(VOCAB_SIZE,EMBEDDING_DIM, input_length=X.shape[1], name=\"Embedding_layer\")(Input_layer)\n",
        "    CNN1_layer1       = Conv1D(100, kernel_size=2, padding=\"same\", activation=\"relu\")(Embedding_layer)\n",
        "    CNN1_layer2       = Conv1D(100, kernel_size=3, padding=\"same\", activation=\"relu\")(Embedding_layer)\n",
        "    CNN1_layer3       = Conv1D(100, kernel_size=4, padding=\"same\", activation=\"relu\")(Embedding_layer)\n",
        "    Concat_layer1     = Concatenate(axis=1)([CNN1_layer1, CNN1_layer2, CNN1_layer3])\n",
        "    Pool_layer1       = MaxPooling1D(pool_size=2)(Concat_layer1)\n",
        "    CNN2_layer1       = Conv1D(100, kernel_size=2, padding=\"same\", activation=\"relu\")(Pool_layer1)\n",
        "    CNN2_layer2       = Conv1D(100, kernel_size=3, padding=\"same\", activation=\"relu\")(Pool_layer1)\n",
        "    CNN2_layer3       = Conv1D(100, kernel_size=4, padding=\"same\", activation=\"relu\")(Pool_layer1)\n",
        "    Concat_layer2     = Concatenate(axis=1)([CNN2_layer1, CNN2_layer2, CNN2_layer3])\n",
        "    Pool_layer2       = MaxPooling1D(pool_size=2)(Concat_layer2)\n",
        "    Flatten_layer     = Flatten()(Pool_layer2)\n",
        "\n",
        "    #Task Specific Layer for Task 1\n",
        "    Dense_layer1a     = Dense(128,activation='relu', name=\"Dense_layer1a\")(Flatten_layer)\n",
        "    Dense_layer1b     = Dense(100,activation='relu', name=\"Dense_layer1b\")(Dense_layer1a)\n",
        "\n",
        "    #Task Specific Layer for Task 2\n",
        "    Dense_layer2a     = Dense(128,activation='relu', name=\"Dense_layer2a\")(Flatten_layer)\n",
        "    Dense_layer2b     = Dense(100,activation='relu', name=\"Dense_layer2b\")(Dense_layer2a)\n",
        "\n",
        "    # Predictions for each task\n",
        "    predictions_task1 = Dense(4, activation='softmax', name=\"predictions_task1\")(Dense_layer1b)\n",
        "    predictions_task2 = Dense(1, activation='sigmoid', name=\"predictions_task2\")(Dense_layer2b)\n",
        "\n",
        "    model= tf.keras.models.Model(Input_layer, [predictions_task1,predictions_task2])\n",
        "    model.compile( loss= {'predictions_task1':'categorical_crossentropy' , 'predictions_task2':'mean_absolute_error' },\n",
        "                   optimizer='adam',\n",
        "                   loss_weights=[alpha,1-alpha],\n",
        "                   metrics={'predictions_task1':'accuracy' , 'predictions_task2':pearson_r },\n",
        "                 )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8rm2xXSgtR_"
      },
      "outputs": [],
      "source": [
        "Multihead_CNN_model = create_multihead_CNN_model(X_train_encoded)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "8NxRk9W2gtR_"
      },
      "source": [
        "Multihead_CNN_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2kuc8tegtR_"
      },
      "outputs": [],
      "source": [
        "Multihead_CNN_model_history = Multihead_CNN_model.fit(X_train_encoded, [Y1_train_encoded,Y2_train_encoded], epochs=40, batch_size=64,validation_split=0.1,\n",
        "                     callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8_1QdhggtR_"
      },
      "source": [
        "### Summarize Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXIKeIS8gtR_"
      },
      "outputs": [],
      "source": [
        "# Summarize history for Task 1\n",
        "plt.plot(Multihead_CNN_model_history.history['predictions_task1_accuracy'])\n",
        "plt.plot(Multihead_CNN_model_history.history['val_predictions_task1_accuracy'])\n",
        "plt.title('Multitasking Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZjo412mgtSA"
      },
      "outputs": [],
      "source": [
        "# Summarize history for Task 2\n",
        "plt.plot(Multihead_CNN_model_history.history['predictions_task2_pearson_r'])\n",
        "plt.plot(Multihead_CNN_model_history.history['val_predictions_task2_pearson_r'])\n",
        "plt.title('Multitasking Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7HOVZVlgtSA"
      },
      "outputs": [],
      "source": [
        "Multitask_Results_Task1['CNN'] ={'Accuracy':Multihead_CNN_model_history.history['predictions_task1_accuracy'][-1],\n",
        "                                  'Val_Accuracy':Multihead_CNN_model_history.history['val_predictions_task1_accuracy'][-1]}\n",
        "Multitask_Results_Task2['CNN'] ={'pearson_r':Multihead_CNN_model_history.history['predictions_task2_pearson_r'][-1],\n",
        "                                  'Val_pearson_r':Multihead_CNN_model_history.history['val_predictions_task2_pearson_r'][-1]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgA-_1r-gtSB"
      },
      "source": [
        "### Plotting Model Architecture"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "drKUxavlgtSB"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(Multihead_CNN_model, to_file='CNN_model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVmgmpRNgtSB"
      },
      "source": [
        "## Performance Comparision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndcc5czKgtSC"
      },
      "source": [
        "### Task 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyGvBEvigtSC"
      },
      "outputs": [],
      "source": [
        "print(\"Multitasking Framework Task 1 Results\\n\")\n",
        "# Print the names of the column\n",
        "print (\"{:<10} {:<15} {:<10}\".format('Model', 'Train Accuracy', ' Val Accuracy'))\n",
        "\n",
        "# print each data item.\n",
        "for key, value in Multitask_Results_Task1.items():\n",
        "    train_acc = round(value['Accuracy'],3)\n",
        "    val_acc   = round(value['Val_Accuracy'],3)\n",
        "    print (\"{:<10} {:<17} {:<10}\".format(key, train_acc, val_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_XIbJV4gtSD"
      },
      "source": [
        "### Task 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzNiedppgtSD"
      },
      "outputs": [],
      "source": [
        "print(\"Multitasking Framework Task 2 Results\\n\")\n",
        "# Print the names of the column\n",
        "print (\"{:<10} {:<15} {:<10}\".format('Model', 'Train Pearson_R', ' Val Pearson_R'))\n",
        "\n",
        "# print each data item.\n",
        "for key, value in Multitask_Results_Task2.items():\n",
        "    train_acc = round(value['pearson_r'],3)\n",
        "    val_acc   = round(value['Val_pearson_r'],3)\n",
        "    print (\"{:<10} {:<17} {:<10}\".format(key, train_acc, val_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6Yi6oFqgtSD"
      },
      "source": [
        "# __Performance Comparision : Single Task Vs Multi Task Framework__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOT7UiP7gtSE"
      },
      "source": [
        "### Task 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K67y8-m1gtSE"
      },
      "outputs": [],
      "source": [
        "print(\"Performance Comparision : Single Task Vs Multi Task Framework\\n\\n\")\n",
        "# Print the names of the column\n",
        "\n",
        "print (\"{:<20} {:<30} {:<20}\".format('Framework','Single Task', 'Multi Task'))\n",
        "print (\"{:<10} {:<15} {:<10} {:<15} {:<10}\".format('Model', 'Train Accuracy', ' Val Accuracy  ','  Train Accuracy', ' Val Accuracy'))\n",
        "\n",
        "# print each data item.\n",
        "for key in ['LSTM','GRU','CNN']:\n",
        "    train_acc1 = round(Results_Task1[key]['Accuracy'],3)\n",
        "    val_acc1   = round(Results_Task1[key]['Val_Accuracy'],3)\n",
        "    train_acc2 = round(Multitask_Results_Task1[key]['Accuracy'],3)\n",
        "    val_acc2   = round(Multitask_Results_Task1[key]['Val_Accuracy'],3)\n",
        "    print (\"{:<10} {:<17} {:<20} {:<17} {:<10}\".format(key, train_acc1, val_acc1,train_acc2, val_acc2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCOefx86gtSE"
      },
      "source": [
        "### Task 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If2c8HqLgtSE"
      },
      "outputs": [],
      "source": [
        "print(\"Performance Comparision : Single Task Vs Multi Task Framework\\n\\n\")\n",
        "# Print the names of the column\n",
        "\n",
        "print (\"{:<20} {:<30} {:<20}\".format('Framework','Single Task', 'Multi Task'))\n",
        "print (\"{:<10} {:<15} {:<10} {:<15} {:<10}\".format('Model', 'Train pearson_r', ' Val pearson_r  ','  Train pearson_r', ' Val pearson_r'))\n",
        "\n",
        "# print each data item.\n",
        "for key in ['LSTM','GRU','CNN']:\n",
        "    train_acc1 = round(Results_Task2[key]['pearson_r'],3)\n",
        "    val_acc1   = round(Results_Task2[key]['Val_pearson_r'],3)\n",
        "    train_acc2 = round(Multitask_Results_Task2[key]['pearson_r'],3)\n",
        "    val_acc2   = round(Multitask_Results_Task2[key]['Val_pearson_r'],3)\n",
        "    print (\"{:<10} {:<17} {:<20} {:<17} {:<10}\".format(key, train_acc1, val_acc1,train_acc2, val_acc2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRn1qWE-gtSF"
      },
      "source": [
        "# __Ensemble Framework__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTXObdg3gtSF"
      },
      "source": [
        "## Task-aware Representations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJADDoktgtSF"
      },
      "outputs": [],
      "source": [
        "Task1_aware_LSTM_Representation = Multihead_LSTM_model.get_layer(\"Dense_layer1b\")\n",
        "Task2_aware_LSTM_Representation = Multihead_LSTM_model.get_layer(\"Dense_layer2b\")\n",
        "\n",
        "Task1_aware_GRU_Representation = Multihead_GRU_model.get_layer(\"Dense_layer1b\")\n",
        "Task2_aware_GRU_Representation = Multihead_GRU_model.get_layer(\"Dense_layer2b\")\n",
        "\n",
        "Task1_aware_CNN_Representation = Multihead_CNN_model.get_layer(\"Dense_layer1b\")\n",
        "Task2_aware_CNN_Representation = Multihead_CNN_model.get_layer(\"Dense_layer2b\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "1c4sAu5_gtSG"
      },
      "source": [
        "Task1_aware_Representations = [Task1_aware_LSTM_Representation,Task1_aware_GRU_Representation,Task1_aware_CNN_Representation]\n",
        "Task2_aware_Representations = [Task2_aware_LSTM_Representation,Task2_aware_GRU_Representation,Task2_aware_CNN_Representation]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UbUNww3gtSH"
      },
      "outputs": [],
      "source": [
        "def create_ensemble_model(Task_aware_Representations):\n",
        "    #Shared Layers\n",
        "    Concat_layer    = Concatenate(axis=1)(Task_aware_Representations)\n",
        "    Dense_layer1    = Dense(128,activation='relu', name=\"Dense_layer1\")(Concat_layer)\n",
        "    Dense_layer2    = Dense(128,activation='relu', name=\"Dense_layer2\")(Dense_layer1)\n",
        "\n",
        "    #Task Specific Layer for Task 1\n",
        "    Dense_layer_task1 = Dense(128,activation='relu', name=\"Dense_layer_task1\")(Dense_layer2)\n",
        "    predictions_task1 = Dense(4, activation='softmax', name=\"predictions_task1\")(Dense_layer_task1)\n",
        "\n",
        "    #Task Specific Layer for Task 1\n",
        "    Dense_layer_task2 = Dense(128,activation='relu', name=\"Dense_layer_task2\")(Dense_layer2)\n",
        "    predictions_task2 = Dense(1, activation='sigmoid', name=\"predictions_task2\")(Dense_layer_task2)\n",
        "\n",
        "    model= tf.keras.models.Model(Input_layer, [predictions_task1,predictions_task2])\n",
        "    model.compile( loss= {'predictions_task1':'categorical_crossentropy' , 'predictions_task2':'mean_absolute_error' },\n",
        "                   optimizer='adam',\n",
        "                   metrics={'predictions_task1':'accuracy' , 'predictions_task2':pearson_r },\n",
        "               )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybcWsKX4gtSH"
      },
      "outputs": [],
      "source": [
        "Multihead_Ensemble_model = create_ensemble_model(Task_aware_Representations)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
